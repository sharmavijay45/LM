# Uniguru-LM

A retrieval-first, indigenous NLP composer integrated into BHIV/Gurukul for KB-grounded responses with Vaani TTS.

## Prerequisites

- Python 3.8+
- Docker
- Access to NAS at \\192.168.0.94\Guruukul_DB
- Credentials: Username Vijay, Password vijay45

## Setup

1. **Clone the repo**:
   ```
   git clone <repo_url>
   cd LMTask
   ```

2. **Install dependencies**:
   ```
   pip install -r requirements.txt
   ```

3. **Mount NAS**:
   ```
   net use G: \\192.168.0.94\Guruukul_DB /user:Vijay vijay45
   ```

4. **Update .env**:
   Ensure the following variables are set:
   ```
   NAS_IP=192.168.0.94
   DOCUMENTS_PATH=\\192.168.0.94\Guruukul_DB\source_documents
   QDRANT_INSTANCE_NAMES=vedas_knowledge_base,vedas_legacy_data
   API_KEY=your_secret_key_here
   ```

5. **Start Qdrant with NAS data**:
   ```
   docker run -d -p 6333:6333 -v G:\qdrant_data:/qdrant/storage qdrant/qdrant
   ```

6. **Run the service**:
   ```
   python -m uvicorn main:app --host 0.0.0.0 --port 8080 --reload
   ```

## API Usage

### Compose Endpoint
- **URL**: POST /compose
- **Headers**: Authorization: your_secret_key_here, Content-Type: application/json
- **Body**:
  ```json
  {
    "query": "What is Vedas?",
    "session_id": "sess123",
    "user_id": "user456"
  }
  ```
- **Response**:
  ```json
  {
    "trace_id": "uuid",
    "final_text": "Answer text",
    "citations": [{"source": "source", "snippet": "snippet"}],
    "audio_url": null
  }
  ```

### Feedback Endpoint
- **URL**: POST /feedback
- **Headers**: Authorization: your_secret_key_here, Content-Type: application/json
- **Body**:
  ```json
  {
    "trace_id": "trace_id",
    "reward": 1.0,
    "feedback_text": "Good response"
  }
  ```

## Troubleshooting

- **Collections not loading**: Check Docker logs: `docker logs <container_id>`
- **NAS not accessible**: Verify IP and credentials, ensure G: is mounted.
- **Port conflict**: Stop other Qdrant: `docker stop <container_id>`
- **No documents found**: Check DOCUMENTS_PATH in .env and NAS access.
- **Qdrant connection failed**: Ensure Qdrant is running on 6333.

## Project Structure

- `main.py`: FastAPI service for /compose and /feedback
- `app/kb_retriever.py`: Retrieves from Qdrant
- `app/composer.py`: Composes answers using Ollama
- `ingest.py`: Ingests documents into Qdrant
- `.env`: Environment variables
- `requirements.txt`: Python dependencies

## Day 1 Deliverables

- Running service with KB-grounded retrieval
- Authenticated API
- Mongo logging
- End-to-end test with curl

Submit 3-line reflection: Humility, Gratitude, Honesty.

## NAS Structure

Based on the provided image, the directory structure and file contents within a Qdrant vector database's storage path on the NAS, specifically under the path qdrant.data/collections/vedas_knowledge_base/0/segments/6b6eB44-82f3-4b01-8117-20aa5d0c9804/payload_storage. This appears to be the persistent storage directory for a Qdrant collection named vedas_knowledge_base, with segment data and payload storage files. These files are likely generated by Qdrant when it indexes and stores embeddings and associated metadata.

### Top-Level Structure (Gurukul_DB/qdrant_data)

- aliases
- collections
  - vedas_knowledge_base
  - vedas_legacy_data
- raft_state.json

### Broader Context (Gurukul_DB)

- metadata
- qdrant_embeddings
- qdrant_fourth_data
- qdrant_legacy_data
- qdrant_new_data
- source_documents
- studymaterial
- env

### Insights and Purpose

Qdrant Database: The presence of folders like qdrant_data, qdrant_embeddings, and raft_state.json indicates that this NAS is hosting a Qdrant database instance. Qdrant is designed for high-performance vector similarity search, making it suitable for RAG applications where retrieving relevant documents based on semantic similarity is key.

Data Segmentation: The structure includes multiple data partitions (qdrant_fourth_data, qdrant_legacy_data, qdrant_new_data), suggesting a strategy to manage data over time or across different updates.

Collections: The collections folder with subfolders like vedas_knowledge_base and vedas_legacy_data indicates that the database is organized into distinct collections, each potentially representing a different domain or dataset (e.g., Vedic knowledge).

Metadata and Embeddings: The metadata and qdrant_embeddings folders suggest that the system stores both the raw data context (metadata) and the vector representations (embeddings) needed for search.

Source and Study Material: The source_documents and studymaterial folders imply that the original data and curated study resources are preserved, which can be used to regenerate embeddings or expand the knowledge base.

### Implications for RAG Project

Data Source: The qdrant_data/collections folder (e.g., vedas_knowledge_base) can serve as the primary data source for retrieval in a RAG system.

Embedding Storage: Use qdrant_embeddings to load precomputed vector representations for efficient similarity search.

Historical Data: Leverage qdrant_legacy_data and vedas_legacy_data for accessing older data if needed for context.

Configuration: The raft_state.json and env files can be used to configure the database and application environment.

Updates: Monitor qdrant_new_data for the latest data additions.

This structure is well-suited for a RAG project, providing a clear separation of data, embeddings, metadata, and configuration files, which can be programmatically accessed and processed by an agentic code platform.